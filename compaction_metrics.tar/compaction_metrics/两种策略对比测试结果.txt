Legacy策略测试

compaction总次数=2315
现实用时=55min(其实还有约1/4的shard依然在处理大量的L0文件)
根据网页端观察，平稳阶段L1文件数约为6.5

（下文中有两个元素的Array表示L0、L1的数值）
总消费文件数=[9202,6009] avg=[3.97,2.60]
    3.97个L0文件：非常贴合pick file配置（4,4,8,2）；
    2.60个L1文件：相比L0消费数目，可以说是占比很大了

消费文件大小=[18718,78472] avg=[8.09,33.90]
    由于读L1算“浪费”，所以此处读扩大为419%

平均单个文件大小=[2.03,13.06]
    L0文件大小符合配置项，L1生成的时候可能有零头，也不得不新建文件，小于16MB也是预期效果

总共节省文件容量（压缩优化）=14207MB avg=6.14MB

总用时（CPU）=22906秒=381.8min avg=9.89秒/次
    在这8.05秒，平均每次做41.99MB的文件读，写入35.85MB

使用L1文件个数 -- compaction次数 -- compaction总用时 -- 平均每次用时
0	51	14413	282.61
1	316	891891	2822.44
2	713	4903831	6877.74
3	677	7753863	11453.27
4	554	9264321	16722.60
5	4	77820	19455.00
对于使用相同的L1文件数目，Legacy的单次用时短于Experimental（见下），这是由于pick策略差，用的L0文件少。




Experimental策略测试（exp1）

compaction总次数=1217
现实用时=25min
根据网页端观察，平稳阶段L1文件数约为6


消费文件数=[9584,2551] avg=[7.88,2.10]
    7.88个L0文件：显著高于pick file配置（4,4,8,2），应该优化算法，避免产生过大的pick；
    2.10个L1文件：本算法思想就是减少每次涉及的L1文件数，<2应该是基本预期效果

消费文件大小=[18702,31372] avg=[15.37,25.78]
    由于读L1算“浪费”，所以此处读扩大为168%

单个文件大小=[1.95,12.30]
    L0文件大小符合配置项，L1生成的时候可能有零头，也不得不新建文件，小于16MB也是预期效果

总共节省文件容量（压缩优化）=14194MB avg=11.66MB

总用时（CPU）=9797秒=163.3min avg=8.05秒/次
    在这8.05秒，平均每次做40.25MB的文件读，写入28.59MB

使用L1文件个数 -- compaction次数 -- compaction总用时 -- 平均每次用时
0	40	18393	459.825
1	383	1362706	3557.9791122715
2	365	2821458	7730.0219178082
3	286	3249375	11361.451048951
4	137	2311579	16872.8394160584
5	4	75456	18864
6	2	57541	28770.5
显然，用上了不多于2个L1文件的compaction用时短。应该控制L1文件使用数目。

（此处应当加上compaction的读写文件大小，因为使用L1多的话，使用L0应该也多，考虑这个因素才好说“效率”。
不过，从理论上分析也是应当减少涉及的L1文件数目比较好，或者说是提高L0文件与L1文件的比例。）
=> 下个Metrics版本会按照使用viceSegments数目统计消费的main/viceSegment总容量、数量，这样就能了解其“效率”。
但是不会优先重写测试报告