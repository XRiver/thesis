\chapter{总结与展望}

\section{总结}

\begin{enumerate}
    \item 本文介绍的compaction算法是通过对最初的“读请求响应超时问题”反复测试、仔细分析后，发现性能瓶颈从而针对性能瓶颈做优化而得到的。这个过程中，离不开本人预先对StellarDB系统的性能监测功能的完善。所以，处理性能优化问题时，需要重视系统的性能统计功能。如果现有的统计能力不能满足问题分析的需求，则应当现场开发统计功能。
    \item “通过分割Memtable给compaction降低读扩大率提供条件”的方案看起来并不直接，像是一种“曲线救国”，但实际上也是根据“读扩大率过高导致大量浪费的I/O”这一现象层层推导得到：为了节省I/O，降低读扩大率，就要减少compaction任务中对L1文件的使用，增加对L0文件的使用。但在随机写入的环境下，现有的flush策略使得所有L1文件都会被使用，所以要先修改flush策略，使调度仅包含少量L1文件的compaction任务变成可能。所以在flush的时候就要控制单个L0文件的主键范围。优化性能需要用逻辑推导解决方案，并做好推翻一些看似理所应当的设计的准备，这样才能发现创新性的解决方案。
    \item 性能优化最终要回归性能数据才有说服力。这次写入性能优化除了compaction算法，实际上还包含了许多参数调节，伴随着多次对比性能测试。这些没有在本文中提及。正是详实的性能数据才能证明优化的有效性。尤其是调参带来的性能变化的数据，对于系统部署时的性能调优更是一笔宝贵的财富。
  \end{enumerate}

\section{展望}

本文所介绍的优化算法在约半年前便已经完成开发、测试，开始在StellarDB的稳定版本内发挥作用。客户的使用反馈证实了此优化确实解决了之前的高并发写入后无法进行读请求的问题。但是对于LSM树写入维护的优化工作从未停止。本优化中的“L0与L1文件选取顺序倒置”的方法应当也可以应用于更底层的compaction过程，从而在底层也实现降低读扩大率的效果。进行性能测试的过程中，有时会出现下层compaction或最底层文件互相合并的操作造成大量I/O浪费的情况，虽然不会对读请求处理产生显著影响，但也是未来优化的方向。